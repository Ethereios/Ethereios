{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethereios/Ethereios/blob/main/Copy_of_pyttitools_PYTTI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UlZcjbmqt7E"
      },
      "source": [
        "# PyTTI-Tools Colab Notebook\n",
        "\n",
        "If you are using PyTTI-tools from a local jupyter server, you might have a better experience with the \"_local\" notebook: https://github.com/pytti-tools/pytti-notebook/blob/main/pyttitools-PYTTI_local.ipynb\n",
        "\n",
        "If you are planning to use google colab with the \"local runtime\" option: this is still the notebook you want.\n",
        "\n",
        "## A very brief history of this notebook\n",
        "\n",
        "The tools and techniques below were pioneered in 2021 by a diverse and distributed collection of amazingly talented ML practitioners, researchers, and artists. The short version of this history is that Katherine Crowson ([@RiversHaveWings](https://twitter.com/RiversHaveWings)) published a notebook inspired by work done by [@advadnoun](https://twitter.com/advadnoun). Katherine's notebook spawned a litany of variants, each with their own twist on the technique or adding a feature to someone else's work. Henry Rachootin ([@sportsracer48](https://twitter.com/sportsracer48)) collected several of the most interesting notebooks and stuck the important bits together with bublegum and scotch tape. Thus was born PyTTI, and there was much rejoicing in sportsracer48's patreon, where it was shared in closed beta for several months. David Marx ([@DigThatData](https://twitter.com/DigThatData)) offered to help tidy up the mess, and sportsracer48 encouraged him to run wild with it. David's contributions snowballed into [PyTTI-Tools](https://github.com/pytti-tools), the engine this notebook sits on top of!\n",
        "\n",
        "If you would like to contribute, receive support, or even just suggest an improvement to the documentation, our issue tracker can be found here: https://github.com/pytti-tools/pytti-core/issues\n",
        "\n",
        "# Instructions\n",
        "\n",
        "Detailed documentation can be found here: https://pytti-tools.github.io/pytti-book/intro.html\n",
        "\n",
        "* Syntax for text prompts and scenes: https://pytti-tools.github.io/pytti-book/SceneDSL.html\n",
        "* Descriptions of all settings: https://pytti-tools.github.io/pytti-book/Settings.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOiwLXZNQTJI"
      },
      "source": [
        "# Step 1. Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSMG0G8EqDix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2685cb7-ddbe-4fcb-a386-9f8294167e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/pytti_tools\n"
          ]
        }
      ],
      "source": [
        "# @title 1.1 Set up storage locations { display-mode: \"form\" }\n",
        "\n",
        "drive_mounted = False\n",
        "gdrive_fpath = '.'\n",
        "\n",
        "#@markdown Mounting your google drive is optional but recommended. You can even restore from google randomly\n",
        "#@markdown kicking you out if you mount your drive.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "mount_gdrive = True # @param{type:\"boolean\"}\n",
        "\n",
        "if mount_gdrive and not drive_mounted:\n",
        "  from google.colab import drive\n",
        "\n",
        "  gdrive_mountpoint = '/content/drive/' #@param{type:\"string\"}\n",
        "  gdrive_subdirectory = 'MyDrive/pytti_tools' #@param{type:\"string\"}\n",
        "  gdrive_fpath = str(Path(gdrive_mountpoint) / gdrive_subdirectory)\n",
        "  try:\n",
        "    drive.mount(gdrive_mountpoint, force_remount = True)\n",
        "    !mkdir -p {gdrive_fpath}\n",
        "    %cd {gdrive_fpath}\n",
        "    drive_mounted = True\n",
        "  except OSError:\n",
        "    print(\n",
        "        \"\\n\\n-----[PYTTI-TOOLS]-------\\n\\n\"\n",
        "        \"If you received a scary OSError and your drive\"\n",
        "        \" was already mounted, ignore it.\"\n",
        "        \"\\n\\n-----[PYTTI-TOOLS]-------\\n\\n\"\n",
        "        )\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrDlHki8rGUy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "86030b60-456c-425f-afc6-86bb41955461"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               0\n",
              "timestamp                2022/08/02 02:08:23.265\n",
              " name                       Tesla V100-SXM2-16GB\n",
              " utilization.gpu [%]                         0 %\n",
              " utilization.memory [%]                      0 %\n",
              " memory.free [MiB]                     16160 MiB\n",
              " memory.used [MiB]                         0 MiB"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31e61ce1-adf4-4a89-8376-7d07e1a357a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <td>2022/08/02 02:08:23.265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>Tesla V100-SXM2-16GB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>utilization.gpu [%]</th>\n",
              "      <td>0 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>utilization.memory [%]</th>\n",
              "      <td>0 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>memory.free [MiB]</th>\n",
              "      <td>16160 MiB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>memory.used [MiB]</th>\n",
              "      <td>0 MiB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31e61ce1-adf4-4a89-8376-7d07e1a357a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31e61ce1-adf4-4a89-8376-7d07e1a357a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31e61ce1-adf4-4a89-8376-7d07e1a357a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# @title 1.2 Check GPU { display-mode: \"form\"}\n",
        "\n",
        "# @markdown Running this cell just gives you information about the GPU attached to your session.\n",
        "\n",
        "#https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf\n",
        "#!nvidia-smi --query-gpu=timestamp,name,utilization.gpu,utilization.memory,memory.free,memory.used --format=csv \n",
        "\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "\n",
        "outv = subprocess.run(['nvidia-smi', '--query-gpu=timestamp,name,utilization.gpu,utilization.memory,memory.free,memory.used', '--format=csv'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "header, rec = outv.split('\\n')[:-1]\n",
        "pd.DataFrame({k:v for k,v in zip(header.split(','), rec.split(','))}, index=[0]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bw5dki6RUZ-c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title 1.3 Install everything else\n",
        "#@markdown Run this cell on a fresh runtime to install the libraries and modules.\n",
        "\n",
        "#@markdown This may take a few minutes. \n",
        "\n",
        "from os.path import exists as path_exists\n",
        "if path_exists(gdrive_fpath):\n",
        "  %cd {gdrive_fpath}\n",
        "\n",
        "def install_pip_deps():\n",
        "    !pip install kornia pytorch-lightning transformers\n",
        "    !pip install jupyter loguru einops PyGLM ftfy regex tqdm hydra-core exrex\n",
        "    !pip install seaborn adjustText bunch matplotlib-label-lines\n",
        "    !pip install --upgrade gdown\n",
        "\n",
        "def instal_gh_deps():\n",
        "  # not sure the \"upgrade\" arg does anything here, just feels like a good idea\n",
        "  !pip install --upgrade git+https://github.com/pytti-tools/AdaBins.git\n",
        "  !pip install --upgrade git+https://github.com/pytti-tools/GMA.git\n",
        "  !pip install --upgrade git+https://github.com/pytti-tools/taming-transformers.git\n",
        "  !pip install --upgrade git+https://github.com/openai/CLIP.git\n",
        "  !pip install --upgrade git+https://github.com/pytti-tools/pytti-core.git\n",
        "\n",
        "try:\n",
        "    import pytti\n",
        "except:\n",
        "    install_pip_deps()\n",
        "    instal_gh_deps()\n",
        "\n",
        "# Preload unopinionated defaults\n",
        "# makes it so users don't have to run every setup cell\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "!python -m pytti.warmup\n",
        "\n",
        "path_to_default = 'config/default.yaml'\n",
        "params = OmegaConf.load(path_to_default)\n",
        "\n",
        "\n",
        "# setup for step 2\n",
        "\n",
        "import math\n",
        "\n",
        "model_default = None\n",
        "random_seed = None\n",
        "seed = random_seed\n",
        "all  = math.inf\n",
        "derive_from_init_aspect_ratio = -1\n",
        "\n",
        "########################\n",
        "\n",
        "try:\n",
        "    import mmc\n",
        "except:\n",
        "    # install mmc\n",
        "    !git clone https://github.com/dmarx/Multi-Modal-Comparators\n",
        "    !pip install poetry\n",
        "    !cd Multi-Modal-Comparators; poetry build\n",
        "    !cd Multi-Modal-Comparators; pip install dist/mmc*.whl\n",
        "    \n",
        "    # optional final step:\n",
        "    #poe napm_installs\n",
        "    !python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\n",
        "# suppress mmc warmup outputs\n",
        "import mmc.loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcqbgebJrLw-"
      },
      "source": [
        "# Step 2: Configure Experiment\n",
        "\n",
        "Edit the parameters, or load saved parameters, then run the model.\n",
        "\n",
        "* https://pytti-tools.github.io/pytti-book/SceneDSL.html\n",
        "* https://pytti-tools.github.io/pytti-book/Settings.html\n",
        "\n",
        "To input previously used settings or settings generated using tools such as https://pyttipanna.xyz/ , jump down to cell 4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc93uiJNouiw"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Settings { display-mode: 'form' } \n",
        "\n",
        "scenes = \"fractal crystal growth | electric pulse | psychedelic | cyberpunk city || cybernetic ecosystem | microscopic systems | molecular machines | futuristic architecture\" # @param{type:\"string\"}\n",
        "scene_suffix = \" watermark:-1:-.95 | text:-2:-1.95 | \" # @param{type:\"string\"}\n",
        "scene_prefix = \"fractals #unrealengine |  photorealism | psychedelic |\" # @param{type:\"string\"}\n",
        "\n",
        "params.scenes = scenes\n",
        "params.scene_prefix = scene_prefix \n",
        "params.scene_suffix = scene_suffix\n",
        "\n",
        "\n",
        "direct_image_prompts   = \"https://scontent.fbom12-1.fna.fbcdn.net/v/t39.30808-6/296635124_5552201578180563_3882948280383018360_n.jpg?_nc_cat=105&ccb=1-7&_nc_sid=0debeb&_nc_ohc=mQciIZD3zCMAX90q9XT&tn=KGbVnJrgADu2FtZM&_nc_ht=scontent.fbom12-1.fna&oh=00_AT9OKPwq7Wi8aZffh-Hvr0VPVjNRUtrg5DV5E7JFcznQ4g&oe=62E8EEFB\" # @param{type:\"string\"}\n",
        "init_image = \"https://scontent.fbom12-1.fna.fbcdn.net/v/t39.30808-6/296635124_5552201578180563_3882948280383018360_n.jpg?_nc_cat=105&ccb=1-7&_nc_sid=0debeb&_nc_ohc=zz5P_5vJ4_0AX91QIoa&tn=KGbVnJrgADu2FtZM&_nc_ht=scontent.fbom12-1.fna&oh=00_AT9xFmVdIF5vmp9VqnfsqaKmKMewcYPYYljcm9uf3om1xQ&oe=62E8EEFB\" # @param{type:\"string\"}\n",
        "direct_init_weight =  \"\" # @param{type:\"string\"}\n",
        "semantic_init_weight = \"\" # @param{type:\"string\"}\n",
        "\n",
        "params.direct_image_prompts = direct_image_prompts\n",
        "params.init_image = init_image\n",
        "params.direct_init_weight = direct_init_weight\n",
        "params.semantic_init_weight = semantic_init_weight\n",
        "\n",
        "\n",
        "interpolation_steps = 200 # @param{type:\"number\"}\n",
        "steps_per_scene =  60000 # @param{type:\"raw\"}\n",
        "steps_per_frame =  150 # @param{type:\"number\"}\n",
        "save_every = steps_per_frame  # @param{type:\"raw\"}\n",
        "\n",
        "params.interpolation_steps = interpolation_steps\n",
        "params.steps_per_scene = steps_per_scene\n",
        "params.steps_per_frame = steps_per_frame\n",
        "params.save_every = save_every"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beKX_dOQmJxb"
      },
      "outputs": [],
      "source": [
        "# @title Misc Run Initialization { display-mode: 'form' } \n",
        "\n",
        "import random\n",
        "\n",
        "#@markdown Check this box to pick up where you left off from a previous run, e.g. if the google colab runtime timed out\n",
        "resume = True #@param{type:\"boolean\"}\n",
        "params.resume = resume\n",
        "\n",
        "seed = random_seed #@param{type:\"raw\"}\n",
        "\n",
        "params.seed = seed\n",
        "if params.seed is None:\n",
        "    params.seed = random.randint(-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcu13O4wyItn"
      },
      "source": [
        "## Image Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki-a6lUNmJxc"
      },
      "outputs": [],
      "source": [
        "# @title General Image Settings { display-mode: 'form' } \n",
        "\n",
        "#@markdown Use `image_model` to select how the model will encode the image\n",
        "image_model = \"Unlimited Palette\" #@param [\"VQGAN\", \"Limited Palette\", \"Unlimited Palette\"]\n",
        "params.image_model = image_model\n",
        "\n",
        "#@markdown image_model | description | strengths | weaknesses\n",
        "#@markdown --- | -- | -- | --\n",
        "#@markdown  VQGAN | classic VQGAN image | smooth images | limited datasets, slow, VRAM intesnsive \n",
        "#@markdown  Limited Palette | pytti differentiable palette | fast,  VRAM scales with `palettes` | pixel images\n",
        "#@markdown  Unlimited Palette | simple RGB optimization | fast, VRAM efficient | pixel images\n",
        "\n",
        "vqgan_model = \"openimages\" #@param [\"imagenet\", \"coco\", \"wikiart\", \"sflckr\", \"openimages\"]\n",
        "params.vqgan_model = vqgan_model\n",
        "\n",
        "#@markdown The output image resolution will be `width` $\\times$ `pixel_size` by height $\\times$ `pixel_size` pixels.\n",
        "#@markdown The easiest way to run out of VRAM is to select `image_model` VQGAN without reducing\n",
        "#@markdown `pixel_size` to $1$.\n",
        "#@markdown For `animation_mode: 3D` the minimum resoultion is about 450 by 400 pixels.\n",
        "\n",
        "\n",
        "width =  1280 # @param {type:\"raw\"}\n",
        "height =   720# @param {type:\"raw\"}\n",
        "\n",
        "params.width = width\n",
        "params.height = height\n",
        "\n",
        "#@markdown the default learning rate is `0.1` for all the VQGAN models\n",
        "#@markdown except openimages, which is `0.15`. For the palette modes the\n",
        "#@markdown default is `0.02`. \n",
        "learning_rate =  model_default #@param{type:\"raw\"}\n",
        "reset_lr_each_frame = True #@param{type:\"boolean\"}\n",
        "\n",
        "params.learning_rate = learning_rate\n",
        "params.reset_lr_each_frame = reset_lr_each_frame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brwmDU4ayd3S"
      },
      "outputs": [],
      "source": [
        "# @title Advanced Color and Appearance options { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "pixel_size = 1#@param{type:\"number\"}\n",
        "smoothing_weight =  0.2#@param{type:\"number\"}\n",
        "\n",
        "params.pixel_size = pixel_size\n",
        "params.smoothing_weight = smoothing_weight\n",
        "\n",
        "\n",
        "#@markdown \"Limited Palette\" specific settings:\n",
        "\n",
        "random_initial_palette = False#@param{type:\"boolean\"}\n",
        "palette_size = 6#@param{type:\"number\"}\n",
        "palettes   = 9#@param{type:\"number\"}\n",
        "\n",
        "params.random_initial_palette = random_initial_palette\n",
        "params.palette_size = palette_size\n",
        "params.palettes = palettes\n",
        "\n",
        "\n",
        "gamma = 1#@param{type:\"number\"}\n",
        "hdr_weight = 0.01#@param{type:\"number\"}\n",
        "palette_normalization_weight = 0.2#@param{type:\"number\"}\n",
        "target_palette = \"\"#@param{type:\"string\"}\n",
        "lock_palette = False #@param{type:\"boolean\"}\n",
        "show_palette = False #@param{type:\"boolean\"}\n",
        "\n",
        "params.gamma = gamma\n",
        "params.hdr_weight = hdr_weight\n",
        "params.palette_normalization_weight = palette_normalization_weight\n",
        "params.target_palette = target_palette\n",
        "params.lock_palette = lock_palette\n",
        "params.show_palette = show_palette"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UQfWugQy2Gf"
      },
      "source": [
        "## Perceptor Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgjlQRzdmJxh"
      },
      "outputs": [],
      "source": [
        "# @title Perceptor Models { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "#@markdown Quality settings from Dribnet's CLIPIT (https://github.com/dribnet/clipit).\n",
        "#@markdown Selecting too many will use up all your VRAM and slow down the model.\n",
        "#@markdown I usually use ViTB32, ViTB16, and RN50 if I get a A100, otherwise I just use ViT32B.\n",
        "\n",
        "#@markdown quality | CLIP models\n",
        "#@markdown --- | --\n",
        "#@markdown  draft | ViTB32 \n",
        "#@markdown  normal | ViTB32, ViTB16 \n",
        "#@markdown  high | ViTB32, ViTB16, RN50\n",
        "#@markdown  best | ViTB32, ViTB16, RN50x4\n",
        "\n",
        "# To do: change this to a multi-select\n",
        "\n",
        "ViTB32 = True #@param{type:\"boolean\"}\n",
        "ViTB16 = True #@param{type:\"boolean\"}\n",
        "ViTL14  = False #@param{type:\"boolean\"}\n",
        "ViTL14_336px  = False #@param{type:\"boolean\"}\n",
        "RN50 = True #@param{type:\"boolean\"}\n",
        "RN101 = False #@param{type:\"boolean\"}\n",
        "RN50x4 = False #@param{type:\"boolean\"}\n",
        "RN50x16 = False #@param{type:\"boolean\"}\n",
        "RN50x64 = False #@param{type:\"boolean\"}\n",
        "\n",
        "\n",
        "params.ViTB32 = ViTB32\n",
        "params.ViTB16 = ViTB16\n",
        "params.ViTL14 = ViTL14\n",
        "params.ViTL14_336px = ViTL14_336px\n",
        "params.RN50 = RN50\n",
        "params.RN101 = RN101\n",
        "params.RN50x4 = RN50x4\n",
        "params.RN50x16 = RN50x16\n",
        "params.RN50x64 = RN50x64\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZDGFx-wSV1R"
      },
      "outputs": [],
      "source": [
        "# @title MMC Perceptors { display-mode: 'form' } \n",
        "\n",
        "#@markdown This cell loads perceptor models via https://github.com/dmarx/multi-modal-comparators. Some model comparisons [here](https://t.co/iShJpm5GjL)\n",
        "\n",
        "# @markdown Select up to three models\n",
        "\n",
        "\n",
        "# @markdown Model 1\n",
        "model1 = \"\" # @param [\"[clip - openai - RN50]\",\"[clip - openai - RN101]\",\"[clip - openai - RN50x4]\",\"[clip - openai - RN50x16]\",\"[clip - openai - RN50x64]\",\"[clip - openai - ViT-B/32]\",\"[clip - openai - ViT-B/16]\",\"[clip - openai - ViT-L/14]\",\"[clip - openai - ViT-L/14@336px]\",\"[clip - mlfoundations - RN50--openai]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--openai]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--openai]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--openai]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50x4--openai]\",\"[clip - mlfoundations - RN50x16--openai]\",\"[clip - mlfoundations - ViT-B-32--openai]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--openai]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--openai]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - mlfoundations - ViT-L-14--openai]\",\"[clip - mlfoundations - ViT-L-14-336--openai]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - sajjjadayobi - clipfa]\",\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_16_epochs]\",\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_32_epochs]\",\"[clip - navervision - kelip_ViT-B/32]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "model2 = \"\" # @param [\"[clip - openai - RN50]\",\"[clip - openai - RN101]\",\"[clip - openai - RN50x4]\",\"[clip - openai - RN50x16]\",\"[clip - openai - RN50x64]\",\"[clip - openai - ViT-B/32]\",\"[clip - openai - ViT-B/16]\",\"[clip - openai - ViT-L/14]\",\"[clip - openai - ViT-L/14@336px]\",\"[clip - mlfoundations - RN50--openai]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--openai]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--openai]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--openai]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50x4--openai]\",\"[clip - mlfoundations - RN50x16--openai]\",\"[clip - mlfoundations - ViT-B-32--openai]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--openai]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--openai]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - mlfoundations - ViT-L-14--openai]\",\"[clip - mlfoundations - ViT-L-14-336--openai]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - sajjjadayobi - clipfa]\",\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_16_epochs]\",\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_32_epochs]\",\"[clip - navervision - kelip_ViT-B/32]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "model3 = \"\" # @param [\"[clip - openai - RN50]\",\"[clip - openai - RN101]\",\"[clip - openai - RN50x4]\",\"[clip - openai - RN50x16]\",\"[clip - openai - RN50x64]\",\"[clip - openai - ViT-B/32]\",\"[clip - openai - ViT-B/16]\",\"[clip - openai - ViT-L/14]\",\"[clip - openai - ViT-L/14@336px]\",\"[clip - mlfoundations - RN50--openai]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--openai]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--openai]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--openai]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50x4--openai]\",\"[clip - mlfoundations - RN50x16--openai]\",\"[clip - mlfoundations - ViT-B-32--openai]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--openai]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--openai]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - mlfoundations - ViT-L-14--openai]\",\"[clip - mlfoundations - ViT-L-14-336--openai]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - sajjjadayobi - clipfa]\",\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_16_epochs]\",\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_32_epochs]\",\"[clip - navervision - kelip_ViT-B/32]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "\n",
        "##########\n",
        "\n",
        "params.use_mmc = False\n",
        "mmc_models = []\n",
        "\n",
        "for model_key in (model1, model2, model3):\n",
        "    if not model_key:\n",
        "        continue\n",
        "    arch, pub, m_id = model_key[1:-1].split(' - ')\n",
        "    params.use_mmc = True\n",
        "    mmc_models.append({\n",
        "        'architecture':arch,\n",
        "        'publisher':pub,\n",
        "        'id':m_id,\n",
        "        })\n",
        "params.mmc_models = mmc_models \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15Fi10X9sTrY"
      },
      "outputs": [],
      "source": [
        "# @title Cutouts { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "#@markdown [Cutouts are how CLIP sees the image.](https://twitter.com/remi_durant/status/1460607677801897990)\n",
        "\n",
        "cutouts = 40#@param{type:\"number\"}\n",
        "cut_pow = 2#@param {type:\"number\"}\n",
        "cutout_border =  .25#@param {type:\"number\"}\n",
        "gradient_accumulation_steps = 1 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "params.cutouts = cutouts\n",
        "params.cut_pow = cut_pow\n",
        "params.cutout_border = cutout_border\n",
        "params.gradient_accumulation_steps = gradient_accumulation_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we_9iRL7uddb"
      },
      "source": [
        "## Animation Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtMmGkcnmJxd"
      },
      "outputs": [],
      "source": [
        "# @title General Animation Settings { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "animation_mode = \"3D\" #@param [\"off\",\"2D\", \"3D\", \"Video Source\"]\n",
        "pre_animation_steps =  250 # @param{type:\"number\"}\n",
        "frames_per_second =  40 # @param{type:\"number\"}\n",
        "\n",
        "params.animation_mode = animation_mode\n",
        "params.pre_animation_steps = pre_animation_steps\n",
        "params.frames_per_second = frames_per_second\n",
        "\n",
        "\n",
        "# @markdown NOTE: prompt masks (`prompt:weight_[mask.png]`) may not work correctly on '`wrap`' or '`mirror`' border mode.\n",
        "border_mode = \"clamp\" # @param [\"clamp\",\"mirror\",\"wrap\",\"black\",\"smear\"]\n",
        "sampling_mode = \"bicubic\" #@param [\"bilinear\",\"nearest\",\"bicubic\"]\n",
        "infill_mode = \"wrap\" #@param [\"mirror\",\"wrap\",\"black\",\"smear\"]\n",
        "\n",
        "params.border_mode = border_mode\n",
        "params.sampling_mode = sampling_mode\n",
        "params.infill_mode = infill_mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TunpOQgZz4sh"
      },
      "outputs": [],
      "source": [
        "# @title Video Input { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "video_path = \"\"# @param{type:\"string\"}\n",
        "frame_stride = 1 #@param{type:\"number\"}\n",
        "reencode_each_frame = False #@param{type:\"boolean\"}\n",
        "\n",
        "params.video_path = video_path\n",
        "params.frame_stride = frame_stride\n",
        "params.reencode_each_frame = reencode_each_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knlDPjBkmd1I"
      },
      "outputs": [],
      "source": [
        "# @title Audio Input { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "input_audio = \"/content/drive/MyDrive/compositions/ethereios sleepless monk/mystic dance/5 Ethereios vs James - Mystic Flow - Master 24 Bit.wav\"# @param{type:\"string\"}\n",
        "input_audio_offset = 0 #@param{type:\"number\"}\n",
        "\n",
        "# @markdown Bandpass filter specification\n",
        "\n",
        "variable_name = 'fAudio'\n",
        "f_center = 1000 # @param{type:\"number\"}\n",
        "f_width = 1990 # @param{type:\"number\"}\n",
        "order = 5 # @param{type:\"number\"}\n",
        "\n",
        "if input_audio:\n",
        "  params.input_audio = input_audio\n",
        "  params.input_audio_offset = input_audio_offset\n",
        "  params.input_audio_filters = [{\n",
        "      'variable_name':variable_name,\n",
        "      'f_center':f_center,\n",
        "      'f_width':f_width,\n",
        "      'order':order\n",
        "    }]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iONOgswvusA9"
      },
      "outputs": [],
      "source": [
        "# @title Image Motion Settings  { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "# @markdown settings whose names end in `_2d` or `_3d` are specific to those animation modes\n",
        "\n",
        "# @markdown `rotate_3d` *must* be a `[w,x,y,z]` rotation (unit) quaternion. Use `rotate_3d: [1,0,0,0]` for no rotation.\n",
        "\n",
        "# @markdown [Learn more about rotation quaternions here](https://eater.net/quaternions).\n",
        "\n",
        "translate_x = \"-1700*sin(radians(1.5))\" # @param{type:\"string\"}\n",
        "translate_y = \"0\" # @param{type:\"string\"}\n",
        "translate_z_3d = \"666*sin((6.66+t)/3)**16\" # @param{type:\"string\"}\n",
        "rotate_3d = \"[cos(radians(1.5)), 0, -sin(radians(1.5))/sqrt(2), sin(radians(1.5))/sqrt(2)]\" # @param{type:\"string\"}\n",
        "rotate_2d = \"0.03\" # @param{type:\"string\"}\n",
        "zoom_x_2d = \"0.01\" # @param{type:\"string\"}\n",
        "zoom_y_2d = \"0.01\" # @param{type:\"string\"}\n",
        "\n",
        "params.translate_x = translate_x\n",
        "params.translate_y = translate_y\n",
        "params.translate_z_3d = translate_z_3d\n",
        "params.rotate_3d = rotate_3d\n",
        "params.rotate_2d = rotate_2d\n",
        "params.zoom_x_2d = zoom_x_2d\n",
        "params.zoom_y_2d = zoom_y_2d\n",
        "\n",
        "\n",
        "\n",
        "#@markdown  3D camera (only used in 3D mode):\n",
        "lock_camera   = True # @param{type:\"boolean\"}\n",
        "field_of_view = 120 # @param{type:\"number\"}\n",
        "near_plane    = 1 # @param{type:\"number\"}\n",
        "far_plane     = 10000 # @param{type:\"number\"}\n",
        "\n",
        "params.lock_camera = lock_camera\n",
        "params.field_of_view = field_of_view\n",
        "params.near_plane = near_plane\n",
        "params.far_plane = far_plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjMDL0jYlOYu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KDTHVHLurtk"
      },
      "outputs": [],
      "source": [
        "# @title Stabilization Weights and Perspective { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "# @markdown `flow_stabilization_weight` is used for `animation_mode: 3D` and `Video Source`\n",
        "\n",
        "direct_stabilization_weight = \"0.1\" # @param{type:\"string\"}\n",
        "semantic_stabilization_weight = \"0.1\" # @param{type:\"string\"}\n",
        "depth_stabilization_weight = \"0.05\" # @param{type:\"string\"}\n",
        "edge_stabilization_weight = \"0.1\" # @param{type:\"string\"}\n",
        "\n",
        "params.direct_stabilization_weight = direct_stabilization_weight\n",
        "params.semantic_stabilization_weight = semantic_stabilization_weight\n",
        "params.depth_stabilization_weight = depth_stabilization_weight\n",
        "params.edge_stabilization_weight = edge_stabilization_weight\n",
        "\n",
        "\n",
        "flow_stabilization_weight = \"0.1\" # @param{type:\"string\"}\n",
        "flow_long_term_samples = 1 # @param{type:\"number\"}\n",
        "\n",
        "params.flow_stabilization_weight = flow_stabilization_weight\n",
        "params.flow_long_term_samples = flow_long_term_samples\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPHz0NeK07LU"
      },
      "source": [
        "## Output Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUFiWh21mJxe"
      },
      "outputs": [],
      "source": [
        "# @title Output and Storage Location { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "# should I move google drive stuff here?\n",
        "\n",
        "models_parent_dir = '.' #@param{type:\"string\"}\n",
        "params.models_parent_dir = models_parent_dir\n",
        "\n",
        "file_namespace = \"twistedukiyo\" #@param{type:\"string\"}\n",
        "params.file_namespace = file_namespace\n",
        "if params.file_namespace == '':\n",
        "  params.file_namespace = 'out'\n",
        "\n",
        "\n",
        "allow_overwrite = False #@param{type:\"boolean\"}\n",
        "base_name = params.file_namespace\n",
        "\n",
        "params.allow_overwrite = allow_overwrite\n",
        "params.base_name = base_name\n",
        "\n",
        "\n",
        "#@markdown `backups` is used for video transfer, so don't lower it if that's what you're doing\n",
        "backups =  2**(params.flow_long_term_samples+1)+1 #@param {type:\"raw\"}\n",
        "params.backups = backups\n",
        "\n",
        "from pytti.Notebook import get_last_file\n",
        "\n",
        "import glob\n",
        "import re\n",
        "# to do: move this logic into pytti-core\n",
        "if not params.allow_overwrite and path_exists(f'images_out/{params.file_namespace}'):\n",
        "  _, i = get_last_file(f'images_out/{params.file_namespace}', \n",
        "                        f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$')\n",
        "  if i == 0:\n",
        "    print(f\"WARNING: file_namespace {params.file_namespace} already has images from run 0\")\n",
        "  elif i is not None:\n",
        "    print(f\"WARNING: file_namespace {params.file_namespace} already has images from runs 0 through {i}\")\n",
        "elif glob.glob(f'images_out/{params.file_namespace}/{params.base_name}_*.png'):\n",
        "  print(f\"WARNING: file_namespace {params.file_namespace} has images which will be overwritten\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqcz3u2QmJxg"
      },
      "outputs": [],
      "source": [
        "# @title Experiment Monitoring { display-mode: 'form', run: 'auto' } \n",
        "\n",
        "display_every = steps_per_frame # @param{type:\"raw\"}\n",
        "clear_every = 0 # @param{type:\"raw\"}\n",
        "display_scale = 1 # @param{type:\"number\"}\n",
        "\n",
        "params.display_every = display_every\n",
        "params.clear_every = clear_every\n",
        "params.display_scale = display_scale\n",
        "\n",
        "show_graphs = True # @param{type:\"boolean\"}\n",
        "use_tensorboard = True #@param{type:\"boolean\"}\n",
        "\n",
        "params.show_graphs = show_graphs\n",
        "params.use_tensorboard = use_tensorboard\n",
        "\n",
        "# needs to be populated or will fail validation\n",
        "params.approximate_vram_usage=False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoLqHzhCmJxh"
      },
      "outputs": [],
      "source": [
        "print(\"SETTINGS:\")\n",
        "print(OmegaConf.to_container(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBVg9av46Yvp"
      },
      "source": [
        "# 2.3 Run it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u1A1VUVmrhrK"
      },
      "outputs": [],
      "source": [
        "#@markdown Execute this cell to start image generation\n",
        "from pytti.workhorse import _main as render_frames\n",
        "import random\n",
        "\n",
        "if (seed is None) or (params.seed is None):\n",
        "  params.seed = random.randint(-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff)\n",
        "\n",
        "render_frames(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7jvv4JOsm1O"
      },
      "source": [
        "# Step 3: Render video\n",
        "You can dowload from the notebook, but it's faster to download from your drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3vMLYoqHsQUU"
      },
      "outputs": [],
      "source": [
        "#@title 3.1 Render video\n",
        "from os.path import exists as path_exists\n",
        "if path_exists(gdrive_fpath):\n",
        "  %cd {gdrive_fpath}\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import change_tqdm_color\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "  \n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from os.path import exists as path_exists\n",
        "from subprocess import Popen, PIPE\n",
        "from PIL import Image, ImageFile\n",
        "from os.path import splitext as split_file\n",
        "import glob\n",
        "from pytti.Notebook import get_last_file\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "try:\n",
        "  params\n",
        "except NameError:\n",
        "  raise RuntimeError(\"ERROR: no parameters. Please run parameters (step 2.1).\")\n",
        "\n",
        "if not path_exists(f\"images_out/{params.file_namespace}\"):\n",
        "  if path_exists(f\"/content/drive/MyDrive\"):\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"ERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"WARNING: Drive is not mounted.\\nERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "\n",
        "#@markdown The first run executed in `file_namespace` is number $0$, the second is number $1$, etc.\n",
        "\n",
        "latest = -1\n",
        "run_number = latest#@param{type:\"raw\"}\n",
        "if run_number == -1:\n",
        "  _, i = get_last_file(f'images_out/{params.file_namespace}', \n",
        "                       f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$')\n",
        "  run_number = i\n",
        "base_name = params.file_namespace if run_number == 0 else (params.file_namespace+f\"({run_number})\")\n",
        "tqdm.write(f'Generating video from {params.file_namespace}/{base_name}_*.png')\n",
        "\n",
        "all_frames = glob.glob(f'images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "all_frames.sort(key = lambda s: int(split_file(s)[0].split('_')[-1]))\n",
        "print(f'found {len(all_frames)} frames matching images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "\n",
        "start_frame = 0#@param{type:\"number\"}\n",
        "all_frames = all_frames[start_frame:]\n",
        "\n",
        "fps =  params.frames_per_second#@param{type:\"raw\"}\n",
        "\n",
        "total_frames = len(all_frames)\n",
        "\n",
        "if total_frames == 0:\n",
        "  #THIS IS NOT AN ERROR. This is the code that would\n",
        "  #make an error if something were wrong.\n",
        "  raise RuntimeError(f\"ERROR: no frames to render in images_out/{params.file_namespace}\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for filename in tqdm(all_frames):\n",
        "  frames.append(Image.open(filename))\n",
        "\n",
        "cmd_in = ['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-']\n",
        "cmd_out = ['-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '1', '-preset', 'veryslow', f'videos/{base_name}.mp4']\n",
        "if params.input_audio:\n",
        "  cmd_in += ['-i', str(params.input_audio), '-acodec', 'libmp3lame']\n",
        "\n",
        "cmd = cmd_in + cmd_out\n",
        "\n",
        "p = Popen(cmd, stdin=PIPE)\n",
        "for im in tqdm(frames):\n",
        "  im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "\n",
        "print(\"Encoding video...\")\n",
        "p.wait()\n",
        "print(\"Video complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CrcQxtI8szYB"
      },
      "outputs": [],
      "source": [
        "#@title 3.2 Download the last exported video\n",
        "from os.path import exists as path_exists\n",
        "if path_exists(gdrive_fpath):\n",
        "  %cd {gdrive_fpath}\n",
        "\n",
        "try:\n",
        "  from pytti.Notebook import get_last_file\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "\n",
        "try:\n",
        "  params\n",
        "except NameError:\n",
        "  #THIS IS NOT AN ERROR. This is the code that would\n",
        "  #make an error if something were wrong.\n",
        "  raise RuntimeError(\"ERROR: please run parameters (step 2.1).\")\n",
        "\n",
        "from google.colab import files\n",
        "try:\n",
        "  base_name = params.file_namespace if run_number == 0 else (params.file_namespace+f\"({run_number})\")\n",
        "  filename = f'{base_name}.mp4'\n",
        "except NameError:\n",
        "  filename, i = get_last_file(f'videos', \n",
        "                       f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?\\\\.mp4)$')\n",
        "\n",
        "if path_exists(f'videos/{filename}'):\n",
        "  files.download(f\"videos/{filename}\")\n",
        "else:\n",
        "  if path_exists(f\"/content/drive/MyDrive\"):\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"ERROR: video videos/{filename} does not exist.\")\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"WARNING: Drive is not mounted.\\nERROR: video videos/{filename} does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRivjyhytVWR"
      },
      "source": [
        "# Sec. 4: Appendix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oLryFpC6rQAI"
      },
      "outputs": [],
      "source": [
        "#@title 4.1 Load settings (optional)\n",
        "#@markdown copy the `SETTINGS:` output from the **Parameters** cell (tripple click to select the whole\n",
        "#@markdown line from `{'scenes'...` to `}`) and paste them in a note to save them for later.\n",
        "\n",
        "#@markdown Paste them here in the future to load those settings again. Running this cell with blank settings won't do anything.\n",
        "from os.path import exists as path_exists\n",
        "if path_exists(gdrive_fpath):\n",
        "  %cd {gdrive_fpath}\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import *\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "  \n",
        "import json, random\n",
        "try:\n",
        "  from bunch import Bunch\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "\n",
        "settings = \"\"#@param{type:\"string\"}\n",
        "#@markdown Check `random_seed` to overwrite the seed from the settings with a random one for some variation.\n",
        "random_seed = False #@param{type:\"boolean\"}\n",
        "\n",
        "if settings != '':\n",
        "  params = load_settings(settings, random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTINLwdVtC12"
      },
      "source": [
        "## 4.2 License\n",
        "\n",
        "```\n",
        "Licensed under the MIT License\n",
        "Copyleft (c) 2021 Henry Rachootin\n",
        "Copyright (c) 2022 David Marx\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in\n",
        "all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "THE SOFTWARE.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iRivjyhytVWR"
      ],
      "name": "Copy of pyttitools-PYTTI.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}